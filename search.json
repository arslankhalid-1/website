[
  {
    "objectID": "assign_02b.html",
    "href": "assign_02b.html",
    "title": "Exploratory Data Analysis",
    "section": "",
    "text": "An exploratory data analysis using the ‚ÄúTEDS2016‚Äù data set.\n\n# loading the data set \nlibrary(haven)\nTEDS_2016 <- read_stata(\"https://github.com/datageneration/home/blob/master/DataProgramming/data/TEDS_2016.dta?raw=true\")\n\n# to read from local drive \n# TEDS_2016 <- read_dta(\"/Users/arslankhalid/Desktop/UTD/Year 3/Spring 2023/Knowledge Mining/Assignments/TEDS_2016.dta\")\n\nOne of the first things to do when starting an exploratory analysis is to check the data for missing values.\n\n#install.packages(\"UpSetR\")\n#install.packages(\"naniar\")\nlibrary(\"naniar\")\nlibrary(\"UpSetR\")\n# how many missing variables?\nn_var_miss(TEDS_2016)\n\n[1] 10\n\n# specific visualiation of the amount of missing data\npar(bg = \"#FCFCF6\")\nvis_miss(TEDS_2016)\n\n\n\n# visualise the patterns of missingness, or rather the combinations of missingness across cases\n\n# only looks at 5 combinations \ngg_miss_upset(TEDS_2016) \n\n\n\n# to look ar all intersections of missing variables \ngg_miss_upset(TEDS_2016, nsets = n_var_miss(TEDS_2016)) \n\n\n\n\nThe figure above shows the most frequent interactions of missing variables in the data. The next step is to see if there is a pattern here and if that affects our analysis in any way. We could consider removing rows that are completely missing. Alternatively, we could choose to drop rows that contain ‚ÄúNA‚Äù. This is shown below.\n\n#install.packages(\"tidyr\")\nlibrary(\"tidyr\")\n\n#Remove rows that contains all NA's\ndf <- TEDS_2016[rowSums(is.na(TEDS_2016)) != ncol(TEDS_2016), ]\n\n#Remove rows with NA's using drop_na()\ndf <- TEDS_2016 %>% drop_na()\n\n# check missing variables again \nn_var_miss(df)\n\n[1] 0\n\n# visual confirmation \npar(bg = \"#FCFCF6\")\nvis_miss(df)\n\n\n\npar(bg = \"#FCFCF6\")\n\nNext we can begin to explore the relationship between Tondu and other variables including female, DPP, age, income, edu, Taiwanese and Econ_worse.\n\nlibrary(ggplot2)\n\nggplot(TEDS_2016, aes(x=female)) + \n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\nplot(edu ~ Tondu, data = TEDS_2016)\n\n\n\n?barplot\n\n# we have to co nvert the variable to a factor and then add labels for the graph to be more meaningful \n\nggplot(TEDS_2016, aes(Tondu)) + \n  geom_bar(aes(y = (..count..)/sum(..count..))) + \n  scale_y_continuous(labels=scales::percent) +\n  ylab(\"Party Support (%)\") + \n  xlab(\"Taiwan Political Parties\")\n\nWarning: The dot-dot notation (`..count..`) was deprecated in ggplot2 3.4.0.\n‚Ñπ Please use `after_stat(count)` instead.\n\n\nDon't know how to automatically pick scale for object of type\n<haven_labelled/vctrs_vctr/double>. Defaulting to continuous.\n\n\n\n\nTEDS_2016$Tondu<-as.numeric(TEDS_2016$Tondu,labels=c(\"Unification now‚Äù, ‚ÄúStatus quo, unif. in future‚Äù, ‚ÄúStatus quo, decide later\", \"Status quo forever\", \"Status quo, indep. in future\", \"Independence now‚Äù, ‚ÄúNo response\"))\nclass(TEDS_2016$Tondu)\n\n[1] \"numeric\"\n\nsummary(TEDS_2016$Tondu)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  1.000   3.000   4.000   4.127   5.000   9.000 \n\n\n--------"
  },
  {
    "objectID": "assign_02b.html#class-notes",
    "href": "assign_02b.html#class-notes",
    "title": "Exploratory Data Analysis",
    "section": "Class Notes",
    "text": "Class Notes\n\nFebruary 15, 2023\n\nStart EDA with Frequency table\n\nGives you the count and categories in data.\n\nHistogram\n\nYou can visualize the data count. Divides the x-axis in to bins and uses the heignt of a bar to display the number of observations. If continuous data do not show a normal distribution then you should investigate why that is the case.\n\nCharts\n\nYou can use the following figure to decide which chart to choose based on the type of variables you are analyzing.\n\n\n\nChart Chooser"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Hello!",
    "section": "",
    "text": "I am Arslan Khalid. Currently I am pursuing a PhD in Public Policy and Political Economy at the University of Texas at Dallas.\n\n\nYou can find out more about my career and research interests here.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUpdated: February 25, 2023"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Current\nPursuing a PhD in Public Policy and Political Economy at University of Texas at Dallas. My area of interest is education policy and I am currently looking into the effects of long-term teacher turnover on student achievement in Texas public schools.\n\n\nEducation\nBSc (Hons) Social Sciences, 2011\n\nLahore University of Management Sciences\n_____________________________________\nPhD Public Policy and Political Economy, 2025\n\n\nUniversity of Texas at Dallas\n_____________________________________\n\n\n\nCertifications\nQualitative Research Summer Intensive, 2022\n\nFundamentals of Qualitative Research\nConducting Qualitative Interviews\nCoding and Analyzing Qualitative Data\n\n_____________________________________\nMasters Course: Evidence Based Decision Making and the Role of Big Data in Public Policy, 2019\n\nInformation Technology University\n_____________________________________\nCertificate in Web and Graphic Design, 2007\n\n\nPunjab University, Lahore\n_____________________________________"
  },
  {
    "objectID": "lab_03.html",
    "href": "lab_03.html",
    "title": "EPPS 6323: Lab03",
    "section": "",
    "text": "R Programming (EDA)\n\nAdapted from Stackoverflow examples) (Objectives: Use plotly, reshape packages, interactive visualization\n\nlibrary(tidyverse)\nlibrary(plotly)\nlibrary(RColorBrewer)\nlibrary(reshape2)\ndata(iris)\nattach(iris)\n# Generate plot on three quantitative variables\niris_plot <- plot_ly(iris,\n                     x = Sepal.Length,\n                     y = Sepal.Width,\n                     z = Petal.Length,\n                     type = \"scatter3d\",\n                     mode = \"markers\",\n                     symbols = 'circle',\n                     size = 0.02)\niris_plot\n\n\n\n\n\n--\nWe could also view the graph in 2 dimensions\n\nfig <- plot_ly(data = iris, x = ~Sepal.Length, y = ~Petal.Length, type = 'scatter',\n  mode = 'markers', symbol = ~Species, symbols = c('circle','x','o'),\n  color = I('black'), marker = list(size = 10))\n\nfig\n\n\n\n\n\n--\nAnother version of the graph\n\nd <- diamonds[sample(nrow(diamonds), 1000), ]\n\nfig <- plot_ly(\n  d, x = ~carat, y = ~price,\n  color = ~carat, size = ~carat\n)\n\nfig\n\n\n\n\n\n--\nMaking a regression surface\n\n# Regression object\n\npetal_lm <- lm(Petal.Length ~ 0 + Sepal.Length + Sepal.Width,\n               data = iris)\n\n#load data\n\npetal_lm <- lm(Petal.Length ~ 0 + Sepal.Length + Sepal.Width,data = iris)\n\n# Setting resolution parameter\ngraph_reso <- 0.05\n\n#Setup Axis\naxis_x <- seq(min(iris$Sepal.Length), max(iris$Sepal.Length), by = graph_reso)\naxis_y <- seq(min(iris$Sepal.Width), max(iris$Sepal.Width), by = graph_reso)\n\n# Regression surface\n# Rearranging data for plotting\npetal_lm_surface <- expand.grid(Sepal.Length = axis_x,Sepal.Width = axis_y,KEEP.OUT.ATTRS = F)\npetal_lm_surface$Petal.Length <- predict.lm(petal_lm, newdata = petal_lm_surface)\npetal_lm_surface <- acast(petal_lm_surface, Sepal.Width ~ Sepal.Length, value.var = \"Petal.Length\")\nhcolors=c(\"orange\",\"blue\",\"green\")[iris$Species]\niris_plot <- plot_ly(iris,\n                     x = ~Sepal.Length,\n                     y = ~Sepal.Width,\n                     z = ~Petal.Length,\n                     text = Species,\n                     type = \"scatter3d\",\n                     mode = \"markers\",\n                     marker = list(color = hcolors),\n                     size=0.02)\n# Add surface\niris_plot <- add_trace(p = iris_plot,\n                       z = petal_lm_surface,\n                       x = axis_x,\n                       y = axis_y,\n                       type = \"surface\",mode = \"markers\",\n                       marker = list(color = hcolors))\niris_plot\n\n\n\n\n\n--\nRegression object\n\npetal_lm <- lm(Petal.Length ~ 0 + Sepal.Length + Sepal.Width, \n               data = iris)"
  },
  {
    "objectID": "assign_02.html",
    "href": "assign_02.html",
    "title": "Lab 01 & Lab 02",
    "section": "",
    "text": "x <- c(1,3,2,5)\nx2 = c(1,6,2)\ny = c(1,4,3)\n\nprint(x) \n\n[1] 1 3 2 5\n\nprint(x2)\n\n[1] 1 6 2\n\nprint(y)\n\n[1] 1 4 3\n\n\n\n\n\n\n\n\nNote:\n\n\n\nYou can also add a code chunk by using keyboard shortcut: ‚Äúcontrol + option + I‚Äù on Mac.\n\n\n\n\n\n\n# the length function counts the number of elements \nlength(x)\n\n[1] 4\n\n\n\n\n\n\nx+y\n\nWarning in x + y: longer object length is not a multiple of shorter object\nlength\n\n\n[1] 2 7 5 6\n\nls() # List objects in the environment\n\n[1] \"x\"  \"x2\" \"y\" \n\nrm(x,y) # Remove objects\nls()\n\n[1] \"x2\"\n\nrm(list=ls()) # Danger! What does this do?  Not recommended!\n\n\n\n\n\n?matrix # to get help on matrices \n        # -> creates a matrix from the given set of values.\n\nx = matrix(data = c(1,2,3,4), nrow = 2, ncol = 2) # Create a 2x2 matrix object\nx\n\n     [,1] [,2]\n[1,]    1    3\n[2,]    2    4\n\nx2 = matrix(c(1,2,3,4),2,2)\nx2\n\n     [,1] [,2]\n[1,]    1    3\n[2,]    2    4\n\nx3 = matrix(c(1,2,3,4),2,2,byrow = TRUE) # What about byrow=F?\nx4 = matrix(c(1,2,3,4),2,2,byrow = FALSE)\n\n\n\n\n\n\n\nNote:\n\n\n\nin the above example ‚Äúx1‚Äù, ‚Äúx2‚Äù, and ‚Äúx4‚Äù are the same matrix.\n\n\n\nx = matrix(data = c(1,2,3,4), nrow = 2, ncol = 2)\n\nsqrt(x) # What does x look like?\n\n         [,1]     [,2]\n[1,] 1.000000 1.732051\n[2,] 1.414214 2.000000\n\nx^2\n\n     [,1] [,2]\n[1,]    1    9\n[2,]    4   16\n\nx = rnorm(50) # Generate a vector of 50 numbers using the rnorm() function\n\ny = x + rnorm(50,mean = 50,sd = .1) # What does rnorm(50,mean=50,sd=.1) generate?\n\ncor(x,y) # Correlation of x and y\n\n[1] 0.9925058\n\nset.seed(1303) # Set the seed for Random Number Generator (RNG) to generate values that are reproducible.\n\nrnorm(50)\n\n [1] -1.1439763145  1.3421293656  2.1853904757  0.5363925179  0.0631929665\n [6]  0.5022344825 -0.0004167247  0.5658198405 -0.5725226890 -1.1102250073\n[11] -0.0486871234 -0.6956562176  0.8289174803  0.2066528551 -0.2356745091\n[16] -0.5563104914 -0.3647543571  0.8623550343 -0.6307715354  0.3136021252\n[21] -0.9314953177  0.8238676185  0.5233707021  0.7069214120  0.4202043256\n[26] -0.2690521547 -1.5103172999 -0.6902124766 -0.1434719524 -1.0135274099\n[31]  1.5732737361  0.0127465055  0.8726470499  0.4220661905 -0.0188157917\n[36]  2.6157489689 -0.6931401748 -0.2663217810 -0.7206364412  1.3677342065\n[41]  0.2640073322  0.6321868074 -1.3306509858  0.0268888182  1.0406363208\n[46]  1.3120237985 -0.0300020767 -0.2500257125  0.0234144857  1.6598706557\n\nset.seed(3) # Try different seeds?\ny = rnorm(100)\n\nset.seed(32) # Try different seeds?\ny2 = rnorm(100)\n\nset.seed(321) # Try different seeds?\ny3 = rnorm(100)\n\n\n\n\n\nmean(y)\n\n[1] 0.01103557\n\nvar(y)\n\n[1] 0.7328675\n\nsqrt(var(y))\n\n[1] 0.8560768\n\nsd(y)\n\n[1] 0.8560768"
  },
  {
    "objectID": "assign_02.html#graphics-using-r-graphics-without-packages",
    "href": "assign_02.html#graphics-using-r-graphics-without-packages",
    "title": "Lab 01 & Lab 02",
    "section": "Graphics using R Graphics (without packages)",
    "text": "Graphics using R Graphics (without packages)\n\nx = rnorm(100)\ny = rnorm(100)\n\npar(bg = \"#FCFCF6\")\nplot(x,y, pch = 20, col = \"blue\") # Scatterplot for two numeric variables by default\n\n\n\nplot(x,y, pch = 20, col = \"blue\",xlab =\"this is the x-axis\",\n     ylab =\"this is the y-axis\",main=\"Plot of X vs Y\") # Add labels\n\n\n\npdf(\"Figure01.pdf\") # Save as pdf, add a path or it will be stored on the project directory\n\n\n\n\n\n\n\nNote:\n\n\n\nüì∫ This 5 minute video goes over how to set graphical parameters using ‚Äúpar‚Äù function and ‚Äúdev.off‚Äù function.\n\n\n\npar(bg = \"#FCFCF6\")\nplot(x,y,pch = 20, col = \"forestgreen\") # Try different colors\n\n\n\nplot(x,y,pch = 20, col = \"indianred3\") \n\n\n\nplot(x,y,pch = 20, col = \"paleturquoise3\") \n\n\n\nplot(x,y,pch = 20, col = \"plum4\") \n\n\n\n#dev.off() # Close the file using the dev.off function\n\npar(bg = \"#FCFCF6\")\n\nx1 = seq(1,10) # Same as x=c(1:10)\nx1\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\nx2 = 1:10\nx2\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\n# x1 and x2 are the same\n\nx = seq(-pi,pi,length = 50)\ny = x\ny\n\n [1] -3.14159265 -3.01336438 -2.88513611 -2.75690784 -2.62867957 -2.50045130\n [7] -2.37222302 -2.24399475 -2.11576648 -1.98753821 -1.85930994 -1.73108167\n[13] -1.60285339 -1.47462512 -1.34639685 -1.21816858 -1.08994031 -0.96171204\n[19] -0.83348377 -0.70525549 -0.57702722 -0.44879895 -0.32057068 -0.19234241\n[25] -0.06411414  0.06411414  0.19234241  0.32057068  0.44879895  0.57702722\n[31]  0.70525549  0.83348377  0.96171204  1.08994031  1.21816858  1.34639685\n[37]  1.47462512  1.60285339  1.73108167  1.85930994  1.98753821  2.11576648\n[43]  2.24399475  2.37222302  2.50045130  2.62867957  2.75690784  2.88513611\n[49]  3.01336438  3.14159265"
  },
  {
    "objectID": "assign_02.html#lab-02",
    "href": "assign_02.html#lab-02",
    "title": "Lab 01 & Lab 02",
    "section": "LAB 02",
    "text": "LAB 02\n\nR Programmng Basic Commands\n(Adapted from ISLR Chapter 3 Lab: Introduction to R)\n\n\nIndexing Data using []\n\nA=matrix(1:16,4,4)\nA\n\n     [,1] [,2] [,3] [,4]\n[1,]    1    5    9   13\n[2,]    2    6   10   14\n[3,]    3    7   11   15\n[4,]    4    8   12   16\n\nA[2,3]\n\n[1] 10\n\nA[c(1,3),c(2,4)]\n\n     [,1] [,2]\n[1,]    5   13\n[2,]    7   15\n\nA[1:3,2:4]\n\n     [,1] [,2] [,3]\n[1,]    5    9   13\n[2,]    6   10   14\n[3,]    7   11   15\n\nA[1:2,]\n\n     [,1] [,2] [,3] [,4]\n[1,]    1    5    9   13\n[2,]    2    6   10   14\n\nA[,1:2]\n\n     [,1] [,2]\n[1,]    1    5\n[2,]    2    6\n[3,]    3    7\n[4,]    4    8\n\nA[1,]\n\n[1]  1  5  9 13\n\nA[-c(1,3),]\n\n     [,1] [,2] [,3] [,4]\n[1,]    2    6   10   14\n[2,]    4    8   12   16\n\nA[-c(1,3),-c(1,3,4)]\n\n[1] 6 8\n\ndim(A)\n\n[1] 4 4\n\n\n\n\nLoading Data from GitHub\n\nAuto=read.table(\"https://raw.githubusercontent.com/karlho/knowledgemining/gh-pages/data/Auto.data\")\n# fix(Auto) # Starting the X11 R data editor\nAuto=read.table(\"https://raw.githubusercontent.com/karlho/knowledgemining/gh-pages/data/Auto.data\",header=T,na.strings=\"?\")\n# fix(Auto)\nAuto=read.csv(\"https://raw.githubusercontent.com/karlho/knowledgemining/gh-pages/data/Auto.csv\",header=T,na.strings=\"?\")\n# fix(Auto)\ndim(Auto)\n\n[1] 397   9\n\nAuto[1:4,]\n\n  mpg cylinders displacement horsepower weight acceleration year origin\n1  18         8          307        130   3504         12.0   70      1\n2  15         8          350        165   3693         11.5   70      1\n3  18         8          318        150   3436         11.0   70      1\n4  16         8          304        150   3433         12.0   70      1\n                       name\n1 chevrolet chevelle malibu\n2         buick skylark 320\n3        plymouth satellite\n4             amc rebel sst\n\nAuto=na.omit(Auto)\ndim(Auto)\n\n[1] 392   9\n\nnames(Auto)\n\n[1] \"mpg\"          \"cylinders\"    \"displacement\" \"horsepower\"   \"weight\"      \n[6] \"acceleration\" \"year\"         \"origin\"       \"name\"        \n\n\n\n\nLoad data from ISLR website\n\nAuto=read.table(\"https://www.statlearning.com/s/Auto.data\",header=T,na.strings=\"?\")\ndim(Auto)\n\n[1] 397   9\n\n\n\n\nAdditional Graphical and Numerical Summaries\n\n# plot(cylinders, mpg)\npar(bg = \"#FCFCF6\")\nplot(Auto$cylinders, Auto$mpg)\n\n\n\nattach(Auto)\nplot(cylinders, mpg)\n\n\n\ncylinders=as.factor(cylinders)\nplot(cylinders, mpg)\n\n\n\nplot(cylinders, mpg, col=\"red\")\n\n\n\nplot(cylinders, mpg, col=\"red\", varwidth=T)\n\n\n\nplot(cylinders, mpg, col=\"red\", varwidth=T,horizontal=T)\n\n\n\nplot(cylinders, mpg, col=\"red\", varwidth=T, xlab=\"cylinders\", ylab=\"MPG\")\n\n\n\nhist(mpg)\n\n\n\nhist(mpg,col=2)\n\n\n\nhist(mpg,col=2,breaks=15)\n\n\n\n#pairs(Auto)\npairs(~ mpg + displacement + horsepower + weight + acceleration, Auto)\n\n\n\nplot(horsepower,mpg)\n\n\n\n# identify(horsepower,mpg,name) # Interactive: point and click the dot to identify cases\nsummary(Auto)\n\n      mpg          cylinders      displacement     horsepower        weight    \n Min.   : 9.00   Min.   :3.000   Min.   : 68.0   Min.   : 46.0   Min.   :1613  \n 1st Qu.:17.50   1st Qu.:4.000   1st Qu.:104.0   1st Qu.: 75.0   1st Qu.:2223  \n Median :23.00   Median :4.000   Median :146.0   Median : 93.5   Median :2800  \n Mean   :23.52   Mean   :5.458   Mean   :193.5   Mean   :104.5   Mean   :2970  \n 3rd Qu.:29.00   3rd Qu.:8.000   3rd Qu.:262.0   3rd Qu.:126.0   3rd Qu.:3609  \n Max.   :46.60   Max.   :8.000   Max.   :455.0   Max.   :230.0   Max.   :5140  \n                                                 NA's   :5                     \n  acceleration        year           origin          name          \n Min.   : 8.00   Min.   :70.00   Min.   :1.000   Length:397        \n 1st Qu.:13.80   1st Qu.:73.00   1st Qu.:1.000   Class :character  \n Median :15.50   Median :76.00   Median :1.000   Mode  :character  \n Mean   :15.56   Mean   :75.99   Mean   :1.574                     \n 3rd Qu.:17.10   3rd Qu.:79.00   3rd Qu.:2.000                     \n Max.   :24.80   Max.   :82.00   Max.   :3.000                     \n                                                                   \n\nsummary(mpg)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   9.00   17.50   23.00   23.52   29.00   46.60 \n\n\n\n\nLinear Regression\n\nptbu=c(\"MASS\",\"ISLR\")\ninstall.packages(ptbu, repos='http://cran.us.r-project.org')\n\n\nThe downloaded binary packages are in\n    /var/folders/md/xwgy73f942v77n3vlc1ydy9w0000gn/T//RtmphfEJpK/downloaded_packages\n\nlapply(ptbu, require, character.only = TRUE)\n\nLoading required package: MASS\n\n\nLoading required package: ISLR\n\n\n\nAttaching package: 'ISLR'\n\n\nThe following object is masked _by_ '.GlobalEnv':\n\n    Auto\n\n\n[[1]]\n[1] TRUE\n\n[[2]]\n[1] TRUE\n\nlibrary(MASS)\nlibrary(ISLR)\n\npar(bg = \"#FCFCF6\")\n\n# Simple Linear Regression\n\n# fix(Boston)\nnames(Boston)\n\n [1] \"crim\"    \"zn\"      \"indus\"   \"chas\"    \"nox\"     \"rm\"      \"age\"    \n [8] \"dis\"     \"rad\"     \"tax\"     \"ptratio\" \"black\"   \"lstat\"   \"medv\"   \n\n# lm.fit=lm(medv~lstat)\nattach(Boston)\nlm.fit=lm(medv~lstat,data=Boston)\nattach(Boston)\n\nThe following objects are masked from Boston (pos = 3):\n\n    age, black, chas, crim, dis, indus, lstat, medv, nox, ptratio, rad,\n    rm, tax, zn\n\nlm.fit=lm(medv~lstat)\nlm.fit\n\n\nCall:\nlm(formula = medv ~ lstat)\n\nCoefficients:\n(Intercept)        lstat  \n      34.55        -0.95  \n\nsummary(lm.fit)\n\n\nCall:\nlm(formula = medv ~ lstat)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-15.168  -3.990  -1.318   2.034  24.500 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 34.55384    0.56263   61.41   <2e-16 ***\nlstat       -0.95005    0.03873  -24.53   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.216 on 504 degrees of freedom\nMultiple R-squared:  0.5441,    Adjusted R-squared:  0.5432 \nF-statistic: 601.6 on 1 and 504 DF,  p-value: < 2.2e-16\n\nnames(lm.fit)\n\n [1] \"coefficients\"  \"residuals\"     \"effects\"       \"rank\"         \n [5] \"fitted.values\" \"assign\"        \"qr\"            \"df.residual\"  \n [9] \"xlevels\"       \"call\"          \"terms\"         \"model\"        \n\ncoef(lm.fit)\n\n(Intercept)       lstat \n 34.5538409  -0.9500494 \n\nconfint(lm.fit)\n\n                2.5 %     97.5 %\n(Intercept) 33.448457 35.6592247\nlstat       -1.026148 -0.8739505\n\npredict(lm.fit,data.frame(lstat=(c(5,10,15))), interval=\"confidence\")\n\n       fit      lwr      upr\n1 29.80359 29.00741 30.59978\n2 25.05335 24.47413 25.63256\n3 20.30310 19.73159 20.87461\n\npredict(lm.fit,data.frame(lstat=(c(5,10,15))), interval=\"prediction\")\n\n       fit       lwr      upr\n1 29.80359 17.565675 42.04151\n2 25.05335 12.827626 37.27907\n3 20.30310  8.077742 32.52846\n\n# What is the differnce between \"conference\" and \"prediction\" difference?\n\nplot(lstat,medv)\nabline(lm.fit)\nabline(lm.fit,lwd=3)\nabline(lm.fit,lwd=3,col=\"red\")\n\n\n\nplot(lstat,medv,col=\"red\")\n\n\n\nplot(lstat,medv,pch=16)\n\n\n\nplot(lstat,medv,pch=\"+\")\n\n\n\nplot(1:20,1:20,pch=1:20)\n\n\n\npar(bg = \"#FCFCF6\")\npar(mfrow=c(2,2))\nplot(lm.fit)\n\n\n\npar(bg = \"#FCFCF6\") # set background color to match that of the website \npar(mfrow = c(3,1), mar = c(2,15,1,15)) # set margins and layout \nplot(predict(lm.fit), residuals(lm.fit))\nplot(predict(lm.fit), rstudent(lm.fit))\nplot(hatvalues(lm.fit))\n\n\n\nwhich.max(hatvalues(lm.fit))\n\n375 \n375 \n\n\n\n\nMultiple Linear Regression\n\nlm.fit=lm(medv~lstat+age,data=Boston)\nsummary(lm.fit)\n\n\nCall:\nlm(formula = medv ~ lstat + age, data = Boston)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-15.981  -3.978  -1.283   1.968  23.158 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 33.22276    0.73085  45.458  < 2e-16 ***\nlstat       -1.03207    0.04819 -21.416  < 2e-16 ***\nage          0.03454    0.01223   2.826  0.00491 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.173 on 503 degrees of freedom\nMultiple R-squared:  0.5513,    Adjusted R-squared:  0.5495 \nF-statistic:   309 on 2 and 503 DF,  p-value: < 2.2e-16\n\nlm.fit=lm(medv~.,data=Boston)\nsummary(lm.fit)\n\n\nCall:\nlm(formula = medv ~ ., data = Boston)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-15.595  -2.730  -0.518   1.777  26.199 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  3.646e+01  5.103e+00   7.144 3.28e-12 ***\ncrim        -1.080e-01  3.286e-02  -3.287 0.001087 ** \nzn           4.642e-02  1.373e-02   3.382 0.000778 ***\nindus        2.056e-02  6.150e-02   0.334 0.738288    \nchas         2.687e+00  8.616e-01   3.118 0.001925 ** \nnox         -1.777e+01  3.820e+00  -4.651 4.25e-06 ***\nrm           3.810e+00  4.179e-01   9.116  < 2e-16 ***\nage          6.922e-04  1.321e-02   0.052 0.958229    \ndis         -1.476e+00  1.995e-01  -7.398 6.01e-13 ***\nrad          3.060e-01  6.635e-02   4.613 5.07e-06 ***\ntax         -1.233e-02  3.760e-03  -3.280 0.001112 ** \nptratio     -9.527e-01  1.308e-01  -7.283 1.31e-12 ***\nblack        9.312e-03  2.686e-03   3.467 0.000573 ***\nlstat       -5.248e-01  5.072e-02 -10.347  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.745 on 492 degrees of freedom\nMultiple R-squared:  0.7406,    Adjusted R-squared:  0.7338 \nF-statistic: 108.1 on 13 and 492 DF,  p-value: < 2.2e-16\n\nlibrary(car)\n\nLoading required package: carData\n\nvif(lm.fit)\n\n    crim       zn    indus     chas      nox       rm      age      dis \n1.792192 2.298758 3.991596 1.073995 4.393720 1.933744 3.100826 3.955945 \n     rad      tax  ptratio    black    lstat \n7.484496 9.008554 1.799084 1.348521 2.941491 \n\nlm.fit1=lm(medv~.-age,data=Boston)\nsummary(lm.fit1)\n\n\nCall:\nlm(formula = medv ~ . - age, data = Boston)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-15.6054  -2.7313  -0.5188   1.7601  26.2243 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  36.436927   5.080119   7.172 2.72e-12 ***\ncrim         -0.108006   0.032832  -3.290 0.001075 ** \nzn            0.046334   0.013613   3.404 0.000719 ***\nindus         0.020562   0.061433   0.335 0.737989    \nchas          2.689026   0.859598   3.128 0.001863 ** \nnox         -17.713540   3.679308  -4.814 1.97e-06 ***\nrm            3.814394   0.408480   9.338  < 2e-16 ***\ndis          -1.478612   0.190611  -7.757 5.03e-14 ***\nrad           0.305786   0.066089   4.627 4.75e-06 ***\ntax          -0.012329   0.003755  -3.283 0.001099 ** \nptratio      -0.952211   0.130294  -7.308 1.10e-12 ***\nblack         0.009321   0.002678   3.481 0.000544 ***\nlstat        -0.523852   0.047625 -10.999  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.74 on 493 degrees of freedom\nMultiple R-squared:  0.7406,    Adjusted R-squared:  0.7343 \nF-statistic: 117.3 on 12 and 493 DF,  p-value: < 2.2e-16\n\nlm.fit1=update(lm.fit, ~.-age)\n\n\n\nNon-linear Transformations of the Predictors\n\nlm.fit2=lm(medv~lstat+I(lstat^2))\nsummary(lm.fit2)\n\n\nCall:\nlm(formula = medv ~ lstat + I(lstat^2))\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-15.2834  -3.8313  -0.5295   2.3095  25.4148 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 42.862007   0.872084   49.15   <2e-16 ***\nlstat       -2.332821   0.123803  -18.84   <2e-16 ***\nI(lstat^2)   0.043547   0.003745   11.63   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.524 on 503 degrees of freedom\nMultiple R-squared:  0.6407,    Adjusted R-squared:  0.6393 \nF-statistic: 448.5 on 2 and 503 DF,  p-value: < 2.2e-16\n\nlm.fit=lm(medv~lstat)\nanova(lm.fit,lm.fit2)\n\nAnalysis of Variance Table\n\nModel 1: medv ~ lstat\nModel 2: medv ~ lstat + I(lstat^2)\n  Res.Df   RSS Df Sum of Sq     F    Pr(>F)    \n1    504 19472                                 \n2    503 15347  1    4125.1 135.2 < 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\npar(mfrow=c(2,2))\npar(bg = \"#FCFCF6\")\nplot(lm.fit2)\n\n\n\nlm.fit5=lm(medv~poly(lstat,5))\nsummary(lm.fit5)\n\n\nCall:\nlm(formula = medv ~ poly(lstat, 5))\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-13.5433  -3.1039  -0.7052   2.0844  27.1153 \n\nCoefficients:\n                 Estimate Std. Error t value Pr(>|t|)    \n(Intercept)       22.5328     0.2318  97.197  < 2e-16 ***\npoly(lstat, 5)1 -152.4595     5.2148 -29.236  < 2e-16 ***\npoly(lstat, 5)2   64.2272     5.2148  12.316  < 2e-16 ***\npoly(lstat, 5)3  -27.0511     5.2148  -5.187 3.10e-07 ***\npoly(lstat, 5)4   25.4517     5.2148   4.881 1.42e-06 ***\npoly(lstat, 5)5  -19.2524     5.2148  -3.692 0.000247 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.215 on 500 degrees of freedom\nMultiple R-squared:  0.6817,    Adjusted R-squared:  0.6785 \nF-statistic: 214.2 on 5 and 500 DF,  p-value: < 2.2e-16\n\nsummary(lm(medv~log(rm),data=Boston))\n\n\nCall:\nlm(formula = medv ~ log(rm), data = Boston)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-19.487  -2.875  -0.104   2.837  39.816 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  -76.488      5.028  -15.21   <2e-16 ***\nlog(rm)       54.055      2.739   19.73   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.915 on 504 degrees of freedom\nMultiple R-squared:  0.4358,    Adjusted R-squared:  0.4347 \nF-statistic: 389.3 on 1 and 504 DF,  p-value: < 2.2e-16\n\n\n\n\nQualitative Predictors\n\n# fix(Carseats)\nnames(Carseats)\n\n [1] \"Sales\"       \"CompPrice\"   \"Income\"      \"Advertising\" \"Population\" \n [6] \"Price\"       \"ShelveLoc\"   \"Age\"         \"Education\"   \"Urban\"      \n[11] \"US\"         \n\nlm.fit=lm(Sales~.+Income:Advertising+Price:Age,data=Carseats)\nsummary(lm.fit)\n\n\nCall:\nlm(formula = Sales ~ . + Income:Advertising + Price:Age, data = Carseats)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.9208 -0.7503  0.0177  0.6754  3.3413 \n\nCoefficients:\n                     Estimate Std. Error t value Pr(>|t|)    \n(Intercept)         6.5755654  1.0087470   6.519 2.22e-10 ***\nCompPrice           0.0929371  0.0041183  22.567  < 2e-16 ***\nIncome              0.0108940  0.0026044   4.183 3.57e-05 ***\nAdvertising         0.0702462  0.0226091   3.107 0.002030 ** \nPopulation          0.0001592  0.0003679   0.433 0.665330    \nPrice              -0.1008064  0.0074399 -13.549  < 2e-16 ***\nShelveLocGood       4.8486762  0.1528378  31.724  < 2e-16 ***\nShelveLocMedium     1.9532620  0.1257682  15.531  < 2e-16 ***\nAge                -0.0579466  0.0159506  -3.633 0.000318 ***\nEducation          -0.0208525  0.0196131  -1.063 0.288361    \nUrbanYes            0.1401597  0.1124019   1.247 0.213171    \nUSYes              -0.1575571  0.1489234  -1.058 0.290729    \nIncome:Advertising  0.0007510  0.0002784   2.698 0.007290 ** \nPrice:Age           0.0001068  0.0001333   0.801 0.423812    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.011 on 386 degrees of freedom\nMultiple R-squared:  0.8761,    Adjusted R-squared:  0.8719 \nF-statistic:   210 on 13 and 386 DF,  p-value: < 2.2e-16\n\nattach(Carseats)\ncontrasts(ShelveLoc)\n\n       Good Medium\nBad       0      0\nGood      1      0\nMedium    0      1\n\n\n\n\nInteraction Terms (including interaction and single effects)\n\nsummary(lm(medv~lstat*age,data=Boston))\n\n\nCall:\nlm(formula = medv ~ lstat * age, data = Boston)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-15.806  -4.045  -1.333   2.085  27.552 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 36.0885359  1.4698355  24.553  < 2e-16 ***\nlstat       -1.3921168  0.1674555  -8.313 8.78e-16 ***\nage         -0.0007209  0.0198792  -0.036   0.9711    \nlstat:age    0.0041560  0.0018518   2.244   0.0252 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.149 on 502 degrees of freedom\nMultiple R-squared:  0.5557,    Adjusted R-squared:  0.5531 \nF-statistic: 209.3 on 3 and 502 DF,  p-value: < 2.2e-16"
  },
  {
    "objectID": "assign_03.html",
    "href": "assign_03.html",
    "title": "Data Analysis",
    "section": "",
    "text": "Step 1 - is to load the data\n\nlibrary(haven)\nlibrary(expss)\nlibrary(ggplot2)\nlibrary(plyr)\n\n# loading data \nTEDS_2016 <- read_stata(\"https://github.com/datageneration/home/blob/master/DataProgramming/data/TEDS_2016.dta?raw=true\")\n\nStep 2 - is making a subset of the data and understanding the variables\n\n# creating a subset \nSub_TED <- subset(TEDS_2016, select = c(\"Tondu\", \"female\", \"DPP\", \"age\", \"income\", \"edu\", \"Taiwanese\", \"Econ_worse\"))\n\n# viewing class of main dependent variable \"Tondu\" \nclass(Sub_TED$Tondu)\n\n[1] \"haven_labelled\" \"vctrs_vctr\"     \"double\"        \n\n# We need this variable to be a factor in order to understand the categories of the variable \nSub_TED$Tondu <- haven::as_factor(Sub_TED$Tondu)\n\n# viewing class and levels of \"Tondu\" again \nclass(Sub_TED$Tondu)\n\n[1] \"factor\"\n\nlevels(Sub_TED$Tondu)\n\n[1] \"Immediate unification\"                                             \n[2] \"Maintain the status quo,move toward unification\"                   \n[3] \"Maintain the status quo, decide either unification or independence\"\n[4] \"Maintain the status quo forever\"                                   \n[5] \"Maintain the status quo,move toward independence\"                  \n[6] \"Immediate independence\"                                            \n[7] \"Nonresponse\"                                                       \n\n\n\nLevels of ‚ÄúTondu‚Äù\n\n\n\n\n\n\nLevel\nDescription\n\n\n\n\n1\nImmediate unification\n\n\n2\nMaintain the status quo, move toward unification\n\n\n3\nMaintain the status quo, decide either unification or independence\n\n\n4\nMaintain the status quo forever\n\n\n5\nMaintain the status quo,move toward independence\n\n\n6\nImmediate independence\n\n\n7\nNonresponse\n\n\n\nWe could convert ‚ÄúTondu‚Äù to a numeric variable using the code below. However, it would be difficult to interpret the results. A more meaningful analysis would be to use Multinomial Logistic regression which transforms the dependent variable and then uses Maximum Likelihood Estimation, rather than least squares, to estimate the parameters.\n\nSub_TED$Tondu<-as.numeric(Sub_TED$Tondu,labels=c(\"Unification now‚Äù, ‚ÄúStatus quo, unif. in future‚Äù, ‚ÄúStatus quo, decide later\", \"Status quo forever\", \"Status quo, indep. in future\", \"Independence now‚Äù, ‚ÄúNo response\"))\n\nclass(Sub_TED$Tondu)\n\n[1] \"numeric\"\n\n# to see class of all variables in data frame \nsapply(Sub_TED, class)\n\n     Tondu     female        DPP        age     income        edu  Taiwanese \n \"numeric\"  \"numeric\"  \"numeric\"  \"numeric\"  \"numeric\"  \"numeric\"  \"numeric\" \nEcon_worse \n \"numeric\" \n\n\nSince all the variables are numeric we can start with a scatterplot\n\nsp1 <- ggplot(Sub_TED, aes(x=age, y=Tondu)) + \n  geom_point(color = \"firebrick\") + \n  theme(panel.background = element_rect(fill = \"#FCFCF6\"))\n\nsp2 <- ggplot(Sub_TED, aes(x=edu, y=Tondu)) + \n  geom_point(color = \"darkolivegreen\") + \n  theme(panel.background = element_rect(fill = \"#FCFCF6\"))\n\nsp3 <- ggplot(Sub_TED, aes(x=income, y=Tondu)) + \n  geom_point(color = \"cadetblue\") + \n  theme(panel.background = element_rect(fill = \"#FCFCF6\"))\n\nsp1\n\n\n\nsp2\n\n\n\nsp3\n\n\n\n\nThe problem with these scatter plots is that even though the dependent variables is coded as numeric it has discrete values and is in fact a categorical variable. A better way to represent the data would be to code the variables properly.\n\n# trying to fit a regression line to the plot \nsp1 + geom_smooth(method = \"lm\", \n            formula = Tondu ~ age)\n\nWarning: Computation failed in `stat_smooth()`\nCaused by error:\n! object 'Tondu' not found\n\n\n\n\n\n\nSub_TED$Tondu <- haven::as_factor(Sub_TED$Tondu)\nclass(Sub_TED$Tondu)\n\n[1] \"factor\"\n\nlevels(Sub_TED$Tondu)\n\n[1] \"1\" \"2\" \"3\" \"4\" \"5\" \"6\" \"7\"\n\n\n\n\n\n\n\n\nNote\n\n\n\nWhen we convert back from numeric to factor we lose the information of the levels. We have to code it back to the variable using the code below.\n\n\n\nSub_TED$Tondu_factor <- revalue(as.factor(Sub_TED$Tondu), c(\n  \"1\" = \"Immediate unification\", \n  \"2\" = \"Maintain the status quo, move toward unification\",\n  \"3\" = \"Maintain the status quo, decide either unification or independence\",\n  \"4\" = \"Maintain the status quo forever\",\n  \"5\" = \"Maintain the status quo,move toward independence\",\n  \"6\" = \"Immediate independence\",\n  \"7\" = \"Nonresponse\"))\n\nlevels(Sub_TED$Tondu_factor)\n\n[1] \"Immediate unification\"                                             \n[2] \"Maintain the status quo, move toward unification\"                  \n[3] \"Maintain the status quo, decide either unification or independence\"\n[4] \"Maintain the status quo forever\"                                   \n[5] \"Maintain the status quo,move toward independence\"                  \n[6] \"Immediate independence\"                                            \n[7] \"Nonresponse\"                                                       \n\n\nNow we can use a bar plot to visualize the data.\n\nbar_Tondu <- ggplot(Sub_TED, aes(x=Tondu_factor )) +\n  geom_bar(fill=\"antiquewhite3\") +\n  theme(axis.text.x = element_text(angle = 90, vjust = 1, hjust = 1),\n        panel.background = element_rect(fill = \"#FCFCF6\")) +\n  coord_flip()\n\nbar_age <- ggplot(Sub_TED, aes(x=age )) +\n  geom_bar(fill=\"darkolivegreen\") +\n  theme(axis.text.x = element_text(angle = 90, vjust = 1, hjust = 1),\n        panel.background = element_rect(fill = \"#FCFCF6\"))\n\n\nbar_edu <- ggplot(Sub_TED, aes(x=edu )) +\n  geom_bar(fill=\"cadetblue\") +\n  theme(axis.text.x = element_text(angle = 90, vjust = 1, hjust = 1),\n        panel.background = element_rect(fill = \"#FCFCF6\"))\n\nbar_income <- ggplot(Sub_TED, aes(x=as.factor(income) )) +\n  geom_bar(fill=\"coral3\") +\n  theme(axis.text.x = element_text(angle = 90, vjust = 1, hjust = 1),\n        panel.background = element_rect(fill = \"#FCFCF6\"))\n\nbar_Tondu\n\n\n\nbar_age\n\n\n\nbar_edu\n\nWarning: Removed 10 rows containing non-finite values (`stat_count()`).\n\n\n\n\nbar_income"
  }
]